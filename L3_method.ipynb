{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d132f85",
   "metadata": {},
   "source": [
    "# Importing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4dffde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompetitionSet2017_3.pkl has 7652945 edges between a total of 64719 vertices.\n",
      "\n",
      "\n",
      "The goal is to predict which of 1000000 unconnectedvertex-pairs\n",
      "in unconnected_vertex_pairs will be connected until 2020.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "#import networkx as nx\n",
    "#from datetime import date\n",
    "#import random\n",
    "\n",
    "NUM_OF_VERTICES_TOTAL = 64719 # number of vertices of the semantic net\n",
    "\n",
    "data_source = 'CompetitionSet2017_3.pkl'\n",
    "#data_source = 'CompetitionSet2017_3.pkl'\n",
    "\n",
    "full_dynamic_graph_sparse, unconnected_vertex_pairs, year_start, years_delta = pickle.load( open( data_source, \"rb\" ) )\n",
    "\n",
    "NUM_OF_EDGES = full_dynamic_graph_sparse[:, 0].size\n",
    "\n",
    "print(data_source+' has '+str(len(full_dynamic_graph_sparse))+' edges between a total of '+str(NUM_OF_VERTICES_TOTAL)+ ' vertices.\\n\\n')\n",
    "print('The goal is to predict which of '+str(len(unconnected_vertex_pairs))+' unconnectedvertex-pairs\\nin unconnected_vertex_pairs will be connected until '+str(year_start+years_delta)+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29fc94f",
   "metadata": {},
   "source": [
    "# Pre-processing data (currently not being used)\n",
    "\n",
    "It seems the data generates a lot of nodes with 0 degree. For the methods we use this is useless since we can only predict new links inside a connected graph, so we will process the data to create an edge list corresponding to the smaller graph. Later on we can use the dictionary here to revert the scores back to the original graph node indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataflat = []\n",
    "\n",
    "for a in full_dynamic_graph_sparse[:, :2]:\n",
    "    data.append([a[0], a[1]])\n",
    "    dataflat.append(a[0])\n",
    "    dataflat.append(a[1])\n",
    "\n",
    "mydict = {}\n",
    "i = 0\n",
    "\n",
    "for item in dataflat:\n",
    "    if(i>0 and item in mydict):\n",
    "        continue\n",
    "    else:    \n",
    "        mydict[item] = i\n",
    "        i = i+1\n",
    "\n",
    "invDict = {v: k for k, v in mydict.items()}\n",
    "\n",
    "numbered = []\n",
    "\n",
    "for [item1, item2] in data:\n",
    "    numbered.append([mydict[item1], mydict[item2]])\n",
    "\n",
    "edge_list = np.array(numbered)\n",
    "\n",
    "NUM_OF_VERTICES = edge_list.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556a1f2",
   "metadata": {},
   "source": [
    "## Exporting edge_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f57585",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"edge_list.txt\", edge_list, fmt='%i',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ac804",
   "metadata": {},
   "source": [
    "# L3 Method (Istvan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f50f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:40:59.519648\n",
      "Building adjacency matrix and degree vector.\n",
      "Found  8746  unconnected nodes.\n",
      "14:43:39.891633\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "import datetime\n",
    "\n",
    "A    = dok_matrix((NUM_OF_VERTICES_TOTAL, NUM_OF_VERTICES_TOTAL))\n",
    "Diag = dok_matrix((NUM_OF_VERTICES_TOTAL, NUM_OF_VERTICES_TOTAL))\n",
    "D    = np.zeros([NUM_OF_VERTICES_TOTAL, 1])\n",
    "\n",
    "print(datetime.datetime.now().time())\n",
    "print(\"Building adjacency matrix and degree vector.\")\n",
    "for a in full_dynamic_graph_sparse[:, :2]:\n",
    "    A[a[0], a[1]] = 1;\n",
    "    A[a[1], a[0]] = 1;\n",
    "\n",
    "D = np.asarray(A.sum(1))\n",
    "\n",
    "print(\"Found \", np.count_nonzero(D==0),\" unconnected nodes.\")\n",
    "\n",
    "D = np.where(D == 0, 1, D) # Adds 1 to the degree on unconnected nodes to avoid div by 0\n",
    "\n",
    "print(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a2204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:43:39.900437\n",
      "Building D^-1/2.\n",
      "14:43:40.771401\n",
      "Computing Ã.\n",
      "14:43:43.655318\n",
      "Computing P.\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().time())\n",
    "print(\"Building D^-1/2.\")\n",
    "i = -1;\n",
    "for d in D:\n",
    "    i += 1;\n",
    "    Diag[i,i] = 1/np.sqrt(d);\n",
    "\n",
    "print(datetime.datetime.now().time())\n",
    "print(\"Computing Ã.\")\n",
    "A_tilde = Diag*A*Diag;\n",
    "\n",
    "print(datetime.datetime.now().time())\n",
    "print(\"Computing P.\")\n",
    "P_scores = A*A_tilde*A;\n",
    "\n",
    "print(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de635e8",
   "metadata": {},
   "source": [
    "# Post process scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_scores = []\n",
    "\n",
    "for item in unconnected_vertex_pairs:\n",
    "    competition_scores.append([item[0], item[1], P_scores[item[0], item[1]]])\n",
    "    \n",
    "competition_scores = np.array(competition_scores)\n",
    "\n",
    "nonzero_scores = 1*10**6 - np.count_nonzero(competition_scores[:, 2] == 0)\n",
    "\n",
    "print(\"Istvan's method computes the scores of \",nonzero_scores,\" links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted index of predictions given the initial array of 1.000.000 predictions\n",
    "sorted_predictions = np.argsort(-competition_scores[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74648cbb",
   "metadata": {},
   "source": [
    "# AUC (for 2014 -> 2017 predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_ROC(data_vertex_pairs, data_solution):\n",
    "    data_solution = np.array(data_solution)\n",
    "    data_vertex_pairs_sorted = data_solution[data_vertex_pairs]\n",
    "    \n",
    "    xpos=[0]\n",
    "    ypos=[0]\n",
    "    ROC_vals=[]\n",
    "    for ii in range(len(data_vertex_pairs_sorted)):\n",
    "        if data_vertex_pairs_sorted[ii]==1:\n",
    "            xpos.append(xpos[-1])\n",
    "            ypos.append(ypos[-1]+1)\n",
    "        if data_vertex_pairs_sorted[ii]==0:\n",
    "            xpos.append(xpos[-1]+1)\n",
    "            ypos.append(ypos[-1])      \n",
    "            ROC_vals.append(ypos[-1])\n",
    "    \n",
    "    ROC_vals=np.array(ROC_vals)/max(ypos)\n",
    "    ypos=np.array(ypos)/max(ypos)\n",
    "    xpos=np.array(xpos)/max(xpos)\n",
    "    \n",
    "    plt.plot(xpos, ypos)\n",
    "    plt.show()\n",
    "    \n",
    "    AUC=sum(ROC_vals)/len(ROC_vals)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TrainSet2014_3_solution.pkl', \"rb\" ) as pkl_file:\n",
    "        unconnected_vertex_pairs_solution = pickle.load(pkl_file)\n",
    "    \n",
    "AUC = calculate_ROC(sorted_predictions, np.array(unconnected_vertex_pairs_solution))\n",
    "print('Area Under Curve for Evaluation: ', AUC,'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444118dd",
   "metadata": {},
   "source": [
    "# Preparing a file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the results for submission.\n",
    "submit_file = \"test_submission_01.json\"\n",
    "all_idx_list_float=list(map(float, sorted_predictions))\n",
    "with open(submit_file, \"w\", encoding=\"utf8\") as json_file:\n",
    "    json.dump(all_idx_list_float, json_file)\n",
    "    \n",
    "print(\"Solution stored as \"+submit_file+\".\\nLooking forward to your submission.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
